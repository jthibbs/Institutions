{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD_rLDAmSVsW"
   },
   "source": [
    "# **Bringing in all data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVbRo6OrQ7Tt"
   },
   "source": [
    "## Bring in GRID table\n",
    "*   Download from here: https://www.grid.ac/downloads\n",
    "*   Select the excress information needed, merge in excel (VLOOKUP) and import here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "dx74Zcy3RT52",
    "outputId": "57b19adc-0d58-43a4-e64b-b5c168bab0f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>acronym</th>\n",
       "      <th>alias</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>link</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid.1001.0</td>\n",
       "      <td>Australian National University</td>\n",
       "      <td>Canberra</td>\n",
       "      <td>Australian Capital Territory</td>\n",
       "      <td>Australia</td>\n",
       "      <td>ANU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-35.277800</td>\n",
       "      <td>149.120500</td>\n",
       "      <td>http://www.anu.edu.au/</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grid.1002.3</td>\n",
       "      <td>Monash University</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.908300</td>\n",
       "      <td>145.138000</td>\n",
       "      <td>http://www.monash.edu/</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grid.1003.2</td>\n",
       "      <td>University of Queensland</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>UQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-27.495964</td>\n",
       "      <td>153.009627</td>\n",
       "      <td>http://www.uq.edu.au/</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grid.1004.5</td>\n",
       "      <td>Macquarie University</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.775259</td>\n",
       "      <td>151.112915</td>\n",
       "      <td>http://mq.edu.au/</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grid.1005.4</td>\n",
       "      <td>UNSW Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>UNSW</td>\n",
       "      <td>University of New South Wales</td>\n",
       "      <td>-33.917731</td>\n",
       "      <td>151.230964</td>\n",
       "      <td>https://www.unsw.edu.au/</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98327</th>\n",
       "      <td>grid.508497.7</td>\n",
       "      <td>Severn Glocon Group (United Kingdom)</td>\n",
       "      <td>Gloucester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.830360</td>\n",
       "      <td>-2.273422</td>\n",
       "      <td>https://www.severnglocon.com/</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98328</th>\n",
       "      <td>grid.508498.8</td>\n",
       "      <td>Universalbeton Heringen (Germany)</td>\n",
       "      <td>Heringen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.458250</td>\n",
       "      <td>10.861440</td>\n",
       "      <td>http://www.universalbeton.de/</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98329</th>\n",
       "      <td>grid.508499.9</td>\n",
       "      <td>University Hospitals of Derby and Burton NHS F...</td>\n",
       "      <td>Uttoxeter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>UHDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.910665</td>\n",
       "      <td>-1.514036</td>\n",
       "      <td>https://www.uhdb.nhs.uk/</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98330</th>\n",
       "      <td>grid.508500.8</td>\n",
       "      <td>Universal-Kugellager-Fabrik (Germany)</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>UKF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.573480</td>\n",
       "      <td>13.329301</td>\n",
       "      <td>http://www.ukf.de/index.php/en/</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98331</th>\n",
       "      <td>grid.508501.9</td>\n",
       "      <td>Universal Music Group (United States)</td>\n",
       "      <td>Santa Monica</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>UMG</td>\n",
       "      <td>UMG Recordings</td>\n",
       "      <td>34.026075</td>\n",
       "      <td>-118.476490</td>\n",
       "      <td>https://www.universalmusic.com/</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98332 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  ...        type\n",
       "0        grid.1001.0  ...   Education\n",
       "1        grid.1002.3  ...   Education\n",
       "2        grid.1003.2  ...   Education\n",
       "3        grid.1004.5  ...   Education\n",
       "4        grid.1005.4  ...   Education\n",
       "...              ...  ...         ...\n",
       "98327  grid.508497.7  ...     Company\n",
       "98328  grid.508498.8  ...     Company\n",
       "98329  grid.508499.9  ...  Healthcare\n",
       "98330  grid.508500.8  ...     Company\n",
       "98331  grid.508501.9  ...     Company\n",
       "\n",
       "[98332 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################\n",
    " ## Bring in pre-merged GRID data: \n",
    "   # Used latest GRID version: 6/29/2020\n",
    "   # Columns include: ID, Name, City, State, Country, Accronym, Alias, Link\n",
    "########################################################################\n",
    "import pandas as pd\n",
    "filename = '/content/grid_full.csv'\n",
    "grid_insts = pd.read_csv(filename)\n",
    "grid_insts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e415digXQMEr"
   },
   "source": [
    "## Get unclean institution data from Solr\n",
    "*   NOTE: In the future, ideally use allofplos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RS--TYFCQfVC"
   },
   "outputs": [],
   "source": [
    "##############################\n",
    " ## Get all the institution names from solr (and their frequency):\n",
    "##############################\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "####### Get the data (per the link Ben gave me):\n",
    "a = requests.get(\"https://api.plos.org/terms?terms.fl=affiliate_facet&terms.limit=1000000&wt=json&indent=true\", stream=True).json()\n",
    "\n",
    "####### Make a df called 'solr_insts' from the data: institution & country columns:\n",
    "insts = a[\"terms\"][\"affiliate_facet\"]\n",
    "institutions = []\n",
    "countries = []\n",
    "count = []\n",
    "for i in range(len(insts)):\n",
    "    if i % 2 == 0:\n",
    "        temp = insts[i].split(', ')\n",
    "        institutions.append(', '.join(temp[0:len(temp)-1]))  ## Some institutions have commas in them\n",
    "        countries.append(temp[len(temp)-1])\n",
    "    else:\n",
    "        count.append(insts[i])\n",
    "\n",
    "solr_insts = pd.DataFrame({'inst': institutions, 'country': countries, 'count': count})\n",
    "\n",
    "####### Print out:\n",
    "solr_insts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "tfusFVDNKept",
    "outputId": "d7002f6c-8347-4766-fd16-677d2e1081a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1189751"
      ]
     },
     "execution_count": 170,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list(solr_insts['count']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xgR2VEfoCyv"
   },
   "source": [
    "## Get unclean institution data from EM and Marketing Cloud (via Sisense):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "O9y3w6g6n6eB",
    "outputId": "91988869-dbb6-42dd-c8c5-31cf163ccca5"
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    " ## Bring in pre-created raw/unclean data from EM & Marketing Cloud (opt-ins)\n",
    "   # I queried EM and Sisense directly to get the authors, editors, reviewers and opt-ins data (BQ only has authors for now). \n",
    "      # Rows are already de-duplicated.\n",
    "########################################################################\n",
    "import pandas as pd\n",
    "filename = '/content/inst_country_city_optins_added.csv'\n",
    "em_insts = pd.read_csv(filename)\n",
    "em_insts = em_insts[em_insts['Institute'].notnull()].reset_index(drop = True)\n",
    "em_insts\n",
    "\n",
    "########################################################################\n",
    "######## DISABLED: GETTING DATA FROM BIGQUERY IS NOT NEEDED FOR NOW: \n",
    "   # NOTE: In the future we should get this data directly from BigQuery. Right now, Editor & Reviewer contact info is not in BigQuery, only EM.\n",
    "     # Per Yanwu: The editor and reviews are not in BQ yet. In EM, the editors and reviewers are joined with address table using peopleid, since address tables are not in BQ, you can not get /city/coutry/email data for editors and reviewers.\n",
    "     # This information will be available at a later date. \n",
    "########################################################################\n",
    "##################################################\n",
    " ## Authenticate yourself to get access to BQ:\n",
    "##################################################\n",
    "#from google.colab import auth\n",
    "#auth.authenticate_user()\n",
    "#print('Authenticated')\n",
    "\n",
    "###############\n",
    " ### Install and import pandas-gbq, define the project id:\n",
    "###############\n",
    "#!pip install pandas-gbq\n",
    "#import pandas_gbq\n",
    "\n",
    "#project_id = \"plos-data\"\n",
    "\n",
    "##################################################\n",
    " ## Get author data from BQ:\n",
    "##################################################\n",
    "###############\n",
    " ### Get author data from BQ\n",
    "   # NOTE: INSTITUTEID is only relevant for exact matches\n",
    "   # NOTE: Affiliation and Institute are sometimes different, use both to help add more name variations.\n",
    "###############\n",
    "#sql_authors = \"\"\"\n",
    "#  SELECT EMAIL, AFFILIATION, INSTITUTE, CITY, COUNTRY\n",
    "#  FROM PLOSDL.EM_AUTHORS\n",
    "#\"\"\"\n",
    "#df_authors = pandas_gbq.read_gbq(sql_authors, project_id=project_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRXpzyySSwAW"
   },
   "source": [
    "# **Parse down Solar & EM data. Create main look-up table AND connect Solr & EM institution names to GRID names through comma separated method**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "EpOwwAJsoBfG",
    "outputId": "4b1ec84f-3749-4973-94ae-fd9d69278841"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst</th>\n",
       "      <th>grid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Chinese Academy of Sciences, Bei...</td>\n",
       "      <td>grid.410726.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Basel, Basel</td>\n",
       "      <td>grid.6612.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harvard Medical School, Boston, Massachusetts</td>\n",
       "      <td>grid.471403.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Swiss Tropical and Public Health Institute, Basel</td>\n",
       "      <td>grid.416786.a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fogarty International Center, National Institu...</td>\n",
       "      <td>grid.453035.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37691</th>\n",
       "      <td>Örebro University, School of Health and Medica...</td>\n",
       "      <td>grid.15895.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37692</th>\n",
       "      <td>Örebro University, Örebro</td>\n",
       "      <td>grid.15895.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37693</th>\n",
       "      <td>Østfold Hospital Trust, Fredrikstad</td>\n",
       "      <td>grid.412938.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37694</th>\n",
       "      <td>Østfold University College, Halden</td>\n",
       "      <td>grid.446040.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37695</th>\n",
       "      <td>Šumava National Park, Vimperk</td>\n",
       "      <td>grid.448331.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37696 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    inst        grid_id\n",
       "0      University of Chinese Academy of Sciences, Bei...  grid.410726.6\n",
       "1                             University of Basel, Basel    grid.6612.3\n",
       "2          Harvard Medical School, Boston, Massachusetts  grid.471403.5\n",
       "3      Swiss Tropical and Public Health Institute, Basel  grid.416786.a\n",
       "4      Fogarty International Center, National Institu...  grid.453035.4\n",
       "...                                                  ...            ...\n",
       "37691  Örebro University, School of Health and Medica...  grid.15895.30\n",
       "37692                          Örebro University, Örebro  grid.15895.30\n",
       "37693                Østfold Hospital Trust, Fredrikstad  grid.412938.5\n",
       "37694                 Østfold University College, Halden  grid.446040.2\n",
       "37695                      Šumava National Park, Vimperk  grid.448331.9\n",
       "\n",
       "[37696 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    " ## Remove Solr institutions that exactly match GRID names or aliases.\n",
    "##################################################\n",
    "temp_grid = grid_insts[['Name', 'alias']].drop_duplicates(subset=['Name'], keep = False)\n",
    "solr_insts = pd.merge(solr_insts, temp_grid, how='left', left_on= 'inst', right_on = 'Name')\n",
    "temp_grid = grid_insts[['Name', 'alias']].drop_duplicates(subset=['alias'], keep = False).dropna()\n",
    "solr_insts = pd.merge(solr_insts, temp_grid, how='left', left_on= 'inst', right_on = 'alias')\n",
    "solr_insts = solr_insts[(solr_insts['Name_x'].isnull()) & (solr_insts['alias_y'].isnull())].reset_index(drop = True).drop(['Name_x', 'alias_x', 'Name_y', 'alias_y'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    " ## (a) Use comma separated method for solr_insts (b) Create main look-up table, starting with these rows linked after comma separation\n",
    "    # NOTE: Aliases can be too generic for using with split method.\n",
    "##################################################\n",
    "###############\n",
    " ### Create 'split_inst' solr variables. Create main look-up table by matching split_inst on GRID Names:\n",
    "###############\n",
    "solr_insts['split_inst'] = solr_insts['inst'].str.split(',').str[0]\n",
    "temp_grid = grid_insts[['Name', 'ID']].drop_duplicates(subset=['Name'], keep = False)\n",
    "main_insts = pd.merge(solr_insts, temp_grid, how='left', left_on= 'split_inst', right_on = 'Name')\n",
    "main_insts = main_insts[main_insts['ID'].notnull()].drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "\n",
    "\n",
    "###############\n",
    " ### Remove matched rows from solr_insts. Then remove unneeded columns from main_insts\n",
    "###############\n",
    "temp_connect = main_insts[['inst', 'ID']]\n",
    "solr_insts = pd.merge(solr_insts, temp_connect, how='left', on = 'inst')\n",
    "solr_insts = solr_insts[solr_insts['ID'].isnull()].reset_index(drop = True).drop('ID', axis=1)\n",
    "\n",
    "main_insts = main_insts[['inst', 'ID']]\n",
    "main_insts.columns = ['inst', 'grid_id']\n",
    "\n",
    "main_insts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "46faWItNsOiD",
    "outputId": "2933464d-4215-4569-cee3-3800102d1973"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    " ## Remove EM Institutes that exactly match GRID names or aliases.\n",
    "##################################################\n",
    "temp_grid = grid_insts[['Name', 'alias']].drop_duplicates(subset=['Name'], keep = False)\n",
    "em_insts = pd.merge(em_insts, temp_grid, how='left', left_on= 'Institute', right_on = 'Name')\n",
    "temp_grid = grid_insts[['Name', 'alias']].drop_duplicates(subset=['alias'], keep = False).dropna()\n",
    "em_insts = pd.merge(em_insts, temp_grid, how='left', left_on= 'Institute', right_on = 'alias')\n",
    "em_insts = em_insts[(em_insts['Name_x'].isnull()) & (em_insts['alias_y'].isnull())].reset_index(drop = True).drop(['Name_x', 'alias_x', 'Name_y', 'alias_y'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    " ## (a) Use comma separated method for em_insts (b) Add matches through comma separated method to main_insts\n",
    "    # NOTE: Aliases and Affiliation can be too generic for using with split method.\n",
    "##################################################\n",
    "###############\n",
    " ### Create 'split_inst' solr variables. Create main look-up table by matching split_inst on GRID Names:\n",
    "###############\n",
    "em_insts['split_inst'] = em_insts['Institute'].str.split(',').str[0]\n",
    "temp_grid = grid_insts[['Name', 'ID']].drop_duplicates(subset=['Name'], keep = False)\n",
    "em_insts = pd.merge(em_insts, temp_grid, how='left', left_on= 'split_inst', right_on = 'Name')\n",
    "\n",
    "temp_main = em_insts[['Institute', 'ID']]\n",
    "temp_main = temp_main[temp_main['ID'].notnull()]\n",
    "temp_main.columns = ['inst', 'grid_id']\n",
    "main_insts = pd.concat([main_insts,temp_main], ignore_index=True)\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first')\n",
    "\n",
    "em_insts = em_insts[em_insts['ID'].isnull()].drop(['Name', 'ID'], axis = 1).reset_index(drop = True)\n",
    "\n",
    "em_insts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0okqId-w1xmV"
   },
   "source": [
    "# **'Clean' and connect Solr & EM institution names to 'clean' GRID names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "id": "vgE3e0jw2E6a",
    "outputId": "c2521c45-7e20-4cf1-eb12-375d84d5fdaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst</th>\n",
       "      <th>country</th>\n",
       "      <th>count</th>\n",
       "      <th>split_inst</th>\n",
       "      <th>connect_inst</th>\n",
       "      <th>connect_split_inst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of South Alabama Mitchell Cancer In...</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>749</td>\n",
       "      <td>University of South Alabama Mitchell Cancer In...</td>\n",
       "      <td>university south alabama mitchell cancer insti...</td>\n",
       "      <td>university south alabama mitchell cancer insti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TNO</td>\n",
       "      <td>NETHERLANDS</td>\n",
       "      <td>422</td>\n",
       "      <td>TNO</td>\n",
       "      <td>tno</td>\n",
       "      <td>tno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>London School of Hygiene and Tropical Medicine...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>388</td>\n",
       "      <td>London School of Hygiene and Tropical Medicine</td>\n",
       "      <td>london school hygiene tropical medicine london</td>\n",
       "      <td>london school hygiene tropical medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Illinois at Urbana-Champaign</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>358</td>\n",
       "      <td>University of Illinois at Urbana-Champaign</td>\n",
       "      <td>university illinois urbana champaign</td>\n",
       "      <td>university illinois urbana champaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University of Michigan</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>348</td>\n",
       "      <td>University of Michigan</td>\n",
       "      <td>university michigan</td>\n",
       "      <td>university michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619079</th>\n",
       "      <td>”Dante Pazzanese” Institute of Cardiology, Sao...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1</td>\n",
       "      <td>”Dante Pazzanese” Institute of Cardiology</td>\n",
       "      <td>dante pazzanese institute cardiology sao paulo...</td>\n",
       "      <td>dante pazzanese institute cardiology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619080</th>\n",
       "      <td>”Dr. Carol Davila” Teaching Hospital of Nephro...</td>\n",
       "      <td>Romania</td>\n",
       "      <td>1</td>\n",
       "      <td>”Dr. Carol Davila” Teaching Hospital of Nephro...</td>\n",
       "      <td>dr carol davila teaching hospital nephrology b...</td>\n",
       "      <td>dr carol davila teaching hospital nephrology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619081</th>\n",
       "      <td>”Golgi Cenci” Foundation, Abbiategrasso</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>”Golgi Cenci” Foundation</td>\n",
       "      <td>golgi cenci foundation abbiategrasso</td>\n",
       "      <td>golgi cenci foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619082</th>\n",
       "      <td>”Stefan cel Mare” University, Faculty of Food ...</td>\n",
       "      <td>Romania</td>\n",
       "      <td>1</td>\n",
       "      <td>”Stefan cel Mare” University</td>\n",
       "      <td>stefan cel mare university faculty food engine...</td>\n",
       "      <td>stefan cel mare university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619083</th>\n",
       "      <td>”Victor Babes” National Institute of Pathology...</td>\n",
       "      <td>Romania</td>\n",
       "      <td>1</td>\n",
       "      <td>”Victor Babes” National Institute of Pathology</td>\n",
       "      <td>victor babes national institute pathology buch...</td>\n",
       "      <td>victor babes national institute pathology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619084 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     inst  ...                                 connect_split_inst\n",
       "0       University of South Alabama Mitchell Cancer In...  ...  university south alabama mitchell cancer insti...\n",
       "1                                                     TNO  ...                                                tno\n",
       "2       London School of Hygiene and Tropical Medicine...  ...            london school hygiene tropical medicine\n",
       "3              University of Illinois at Urbana-Champaign  ...               university illinois urbana champaign\n",
       "4                                  University of Michigan  ...                                university michigan\n",
       "...                                                   ...  ...                                                ...\n",
       "619079  ”Dante Pazzanese” Institute of Cardiology, Sao...  ...               dante pazzanese institute cardiology\n",
       "619080  ”Dr. Carol Davila” Teaching Hospital of Nephro...  ...       dr carol davila teaching hospital nephrology\n",
       "619081            ”Golgi Cenci” Foundation, Abbiategrasso  ...                             golgi cenci foundation\n",
       "619082  ”Stefan cel Mare” University, Faculty of Food ...  ...                         stefan cel mare university\n",
       "619083  ”Victor Babes” National Institute of Pathology...  ...          victor babes national institute pathology\n",
       "\n",
       "[619084 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    " ## Create method to create new column of 'clean' institution names. Apply to EM & solr inst & split insts, along with GRID data. Also use cleaned EM's affiliation\n",
    "##################################################\n",
    "###############\n",
    " ### Function to clean strings of a dataset's column:\n",
    "###############\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "def clean_column(dataset):\n",
    "    clean = []\n",
    "    ## Remove stop words from ONLY english or MANY languages: Currently only using english words\n",
    "#    stop_words = list(set(list(set(stopwords.words('english'))) + list(set(stopwords.words('spanish'))) + list(set(stopwords.words('arabic'))) + list(set(stopwords.words('german'))) + list(set(stopwords.words('french'))) + list(set(stopwords.words('russian')))))\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    for i in range(len(dataset)):\n",
    "        temp = []\n",
    "        temp = str(dataset[i]).lower()\n",
    "        ## Replace punctuation as spaces:\n",
    "        translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) # map punctuation to space\n",
    "        temp = temp.translate(translator)\n",
    "        temp = temp.strip()\n",
    "        temp = word_tokenize(temp)\n",
    "        temp = [i for i in temp if not i in stop_words]\n",
    "        ## get rid of 1 character words:\n",
    "        temp = [i for i in temp if (len(i) > 1)]\n",
    "        ######## NOTE: This is where you'd put in code to replace EM words not in the other data to similar word in the other data (import in the csv with word connectors first):\n",
    "        clean.append(TreebankWordDetokenizer().detokenize(temp))\n",
    "    return clean\n",
    "\n",
    "\n",
    "###############\n",
    " ### Use the clean_column function on each dataset:\n",
    "###############\n",
    "solr_insts['connect_inst'] = clean_column(solr_insts['inst'])\n",
    "solr_insts['connect_split_inst'] = clean_column(solr_insts['split_inst'])\n",
    "em_insts['connect_inst'] = clean_column(em_insts['Institute'])\n",
    "em_insts['connect_split_inst'] = clean_column(em_insts['split_inst'])\n",
    "em_insts['connect_affiliation'] = clean_column(em_insts['Affiliation'])\n",
    "grid_insts['connect_inst'] = clean_column(grid_insts['Name'])\n",
    "\n",
    "solr_insts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "id": "WzefVdMy4a3H",
    "outputId": "27ffb942-f891-4f49-d2ca-2c3a5292062d"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    " ## (a) Use 'cleaned inst' method to connect to GRID names on: solr's inst and split_inst and em's Institute, split_inst and Affiliation:\n",
    "   # remove all matches from solr or em (respecively) except matched EM 'clean_affiliations'. \n",
    "##################################################\n",
    "###############\n",
    " ### Method to connect clean inst to clean GRID, then remove from dataset and add to main_insts data:\n",
    "###############\n",
    "def match_remove_insts(dataset, clean_var, raw_var):\n",
    "    temp_grid = grid_insts[['connect_inst', 'ID']].drop_duplicates(subset=['connect_inst'], keep = False)\n",
    "    temp_grid.columns = ['GRID_connector', \"ID\"]\n",
    "    temp_dataset = pd.merge(dataset, temp_grid, how='left', left_on= clean_var, right_on = 'GRID_connector')\n",
    "    temp_main = temp_dataset[[raw_var, 'ID']]\n",
    "    temp_main = temp_main[temp_main['ID'].notnull()]\n",
    "    temp_main.columns = ['inst', 'grid_id']\n",
    "    temp_main_data = pd.concat([main_insts,temp_main], ignore_index=True)\n",
    "    temp_main_data = temp_main_data.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "    temp_dataset = temp_dataset[temp_dataset['ID'].isnull()].drop(['ID', 'GRID_connector'], axis = 1).reset_index(drop = True)\n",
    "    return temp_dataset, temp_main_data\n",
    "\n",
    "\n",
    "###############\n",
    " ### Use the method: solr's inst and split_inst and em's Institute, split_inst:\n",
    "###############\n",
    "#solr_insts, main_insts = match_remove_insts(solr_insts, 'connect_inst', 'inst')\n",
    "#solr_insts, main_insts = match_remove_insts(solr_insts, 'connect_split_inst', 'inst')\n",
    "em_insts, main_insts = match_remove_insts(em_insts, 'connect_inst', 'Institute')\n",
    "em_insts, main_insts = match_remove_insts(em_insts, 'connect_split_inst', 'Institute')\n",
    "\n",
    "\n",
    "###############\n",
    " ### Connect on EM's 'connect_affiliation' but DON'T remove rows from EM:\n",
    "###############\n",
    "temp_grid = grid_insts[['connect_inst', 'ID']].drop_duplicates(subset=['connect_inst'], keep = False)\n",
    "em_insts = pd.merge(em_insts, temp_grid, how='left', left_on= 'connect_affiliation', right_on = 'connect_inst')\n",
    "temp_main = em_insts[['Institute', 'ID']]\n",
    "temp_main = temp_main[temp_main['ID'].notnull()]\n",
    "temp_main.columns = ['inst', 'grid_id']\n",
    "main_insts = pd.concat([main_insts,temp_main], ignore_index=True)\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "em_insts = em_insts.drop(['ID'], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "####################### NOTE: Messed up on the match_remove_insts() for em_insts (creates bad column names). The below is a temporary fix to deal with this error:\n",
    "em_insts = em_insts.drop(['connect_inst_y', 'ID'], axis = 1)\n",
    "em_insts.rename(columns={'connect_inst_x':'connect_inst'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKqLomCx4w0-"
   },
   "source": [
    "# Email domain to GRID link matching: over 75 instances of an institute by email domain in EM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "0LkZZpIxXqIQ",
    "outputId": "3abf4305-dc9b-4ea1-b6ab-5cb1de9fc737"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst</th>\n",
       "      <th>grid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Chinese Academy of Sciences, Bei...</td>\n",
       "      <td>grid.410726.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Basel, Basel</td>\n",
       "      <td>grid.6612.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harvard Medical School, Boston, Massachusetts</td>\n",
       "      <td>grid.471403.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Swiss Tropical and Public Health Institute, Basel</td>\n",
       "      <td>grid.416786.a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fogarty International Center, National Institu...</td>\n",
       "      <td>grid.453035.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113579</th>\n",
       "      <td>Norwegian University of Life SciencesNorwegian...</td>\n",
       "      <td>grid.19477.3c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113580</th>\n",
       "      <td>University of Bergen &amp; Haukeland University Ho...</td>\n",
       "      <td>grid.7914.b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113581</th>\n",
       "      <td>Faculty of Landscape Planning, Horticulture an...</td>\n",
       "      <td>grid.6341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113582</th>\n",
       "      <td>PFH Private Hochschule Gottingen</td>\n",
       "      <td>grid.462770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113583</th>\n",
       "      <td>Tulane</td>\n",
       "      <td>grid.265219.b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113584 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     inst        grid_id\n",
       "0       University of Chinese Academy of Sciences, Bei...  grid.410726.6\n",
       "1                              University of Basel, Basel    grid.6612.3\n",
       "2           Harvard Medical School, Boston, Massachusetts  grid.471403.5\n",
       "3       Swiss Tropical and Public Health Institute, Basel  grid.416786.a\n",
       "4       Fogarty International Center, National Institu...  grid.453035.4\n",
       "...                                                   ...            ...\n",
       "113579  Norwegian University of Life SciencesNorwegian...  grid.19477.3c\n",
       "113580  University of Bergen & Haukeland University Ho...    grid.7914.b\n",
       "113581  Faculty of Landscape Planning, Horticulture an...    grid.6341.0\n",
       "113582                   PFH Private Hochschule Gottingen  grid.462770.0\n",
       "113583                                             Tulane  grid.265219.b\n",
       "\n",
       "[113584 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    " ## Use domain matching on domains with over 75 instances of 'connect_inst' for em_insts\n",
    "    # remove company websites by removing GRID['type'] == 'company' (to remove gmail, yahoo, etc)\n",
    "##################################################\n",
    "###############\n",
    " ### Make the domain connectors for EM (1st email only) and GRID data. Then connect grid's ID onto em_insts\n",
    "    # remove company websites by removing GRID['type'] == 'company'\n",
    "###############\n",
    "### Create 'domain_connect'\n",
    "em_insts['domain_connect'] = em_insts['Email'].str.split(\";\",1).str[0]\n",
    "temp_grid = grid_insts[grid_insts['type'] != \"Company\"]\n",
    "temp_grid['domain_connect'] = temp_grid['link'].str.split(\"www.\",1).str[1].str[:-1]\n",
    "temp_grid = temp_grid[['domain_connect', 'ID']].dropna().drop_duplicates(subset=['domain_connect'], keep = False)\n",
    "em_insts = pd.merge(em_insts, temp_grid, how='left', on=['domain_connect'])\n",
    "\n",
    "###############\n",
    " ### Create a temp dataset, de-duplicating by email domain.\n",
    "###############\n",
    "temp_domain_data = em_insts.drop_duplicates(subset=['Email'], keep = 'first')\n",
    "temp_domain_data['concat'] = temp_domain_data['domain_connect'] + temp_domain_data['connect_inst']\n",
    "\n",
    "###############\n",
    " ### Find and limit temp dataset to institute by domain connections with over 75 unique email instances:\n",
    "###############\n",
    "import nltk\n",
    "dom_agg = nltk.FreqDist(temp_domain_data['concat'])\n",
    "dom_agg = dict((k, v) for k, v in dom_agg.items() if v > 74)              ######################### JUST CHANGE THIS '75' TO MAKE REDO FOR AT LEAST 50 INSTANCES\n",
    "dom_list = list(dom_agg.keys())\n",
    "temp_domain_data = temp_domain_data[temp_domain_data['concat'].isin(dom_list)]\n",
    "\n",
    "###############\n",
    " ### Put inst - domain connections with over 75 unique email instances onto main_insts\n",
    "###############\n",
    "to_main_data = temp_domain_data[['Institute', 'ID']]\n",
    "to_main_data = to_main_data[to_main_data['ID'].notnull()]\n",
    "to_main_data.columns = ['inst', 'grid_id']\n",
    "main_insts = pd.concat([main_insts,to_main_data], ignore_index=True)\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "\n",
    "###############\n",
    " ### Remove inst - domain connections from EM:\n",
    "###############\n",
    "em_insts = em_insts[~em_insts['Institute'].isin(to_main_data['inst'])].reset_index(drop = True).drop('ID', axis=1)\n",
    "\n",
    "main_insts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBvVA5ftt_Zt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CO4mTpdC0cv"
   },
   "source": [
    "# Option to save data and export back in before using Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "7e7XWaGzYCdM",
    "outputId": "b2bc22e0-39d6-4253-fc08-de8ec4f2915b"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_2c76f9fc-b359-4da3-9df9-1746a1884282\", \"main_insts.csv\", 130258681)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_d4b06119-1709-4d75-9eb9-93a0a0f8f28c\", \"em_insts.csv\", 108430443)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_a764ded7-2aa0-4022-ad96-14048e958688\", \"solr_insts.csv\", 78940456)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################################################\n",
    " ## Export/download the data\n",
    "   ############ RECOMMENDED: Google colab can disconnect and reset if left idle for too long (e.g. doing Dimensions stuff overnight)\n",
    "##################################################\n",
    "###############\n",
    " ### Download main_insts\n",
    "###############\n",
    "from google.colab import files\n",
    "main_insts.to_csv('main_insts.csv')\n",
    "files.download('main_insts.csv')\n",
    "\n",
    "###############\n",
    " ### Download em_insts\n",
    "###############\n",
    "em_insts.to_csv('em_insts.csv')\n",
    "files.download('em_insts.csv')\n",
    "\n",
    "###############\n",
    " ### Download solr_insts\n",
    "###############\n",
    "solr_insts.to_csv('solr_insts.csv')\n",
    "files.download('solr_insts.csv')\n",
    "\n",
    "###############\n",
    " ### Download grid_insts (in case you want the inst_connect column already there)\n",
    "###############\n",
    "#grid_insts.to_csv('grid_insts.csv')\n",
    "#files.download('grid_insts.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "id": "8UE1ujhgPOem",
    "outputId": "a535e531-15de-4caf-b72d-b68e965033cd"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    " ## Import back in the data\n",
    "   # Remove the first column because it loads out and in the index\n",
    "##################################################\n",
    "import pandas as pd\n",
    "f = '/content/grid_insts.csv'\n",
    "grid_insts = pd.read_csv(f)\n",
    "grid_insts = grid_insts.iloc[:,1:]\n",
    "f = '/content/main_insts.csv'\n",
    "main_insts = pd.read_csv(f)\n",
    "main_insts = main_insts.iloc[:,1:]\n",
    "f = '/content/em_insts.csv'\n",
    "em_insts = pd.read_csv(f)\n",
    "em_insts = em_insts.iloc[:,1:]\n",
    "f = '/content/solr_insts.csv'\n",
    "solr_insts = pd.read_csv(f)\n",
    "solr_insts = solr_insts.iloc[:,1:]\n",
    "\n",
    "em_insts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIcscn9fX6ai"
   },
   "source": [
    "# Use Dimensions extract_affiliation in batches to get em and solr matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "y7xrcWPck7BB",
    "outputId": "5b360456-832b-4279-ae15-895e8874d0ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst</th>\n",
       "      <th>country</th>\n",
       "      <th>count</th>\n",
       "      <th>split_inst</th>\n",
       "      <th>connect_inst</th>\n",
       "      <th>connect_split_inst</th>\n",
       "      <th>inst_no_punct</th>\n",
       "      <th>country_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Freelance Science Writer, Sherborn, Massachusetts</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>91</td>\n",
       "      <td>Freelance Science Writer</td>\n",
       "      <td>freelance science writer sherborn massachusetts</td>\n",
       "      <td>freelance science writer</td>\n",
       "      <td>Freelance Science Writer  Sherborn  Massachusetts</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epicentre, Paris</td>\n",
       "      <td>France</td>\n",
       "      <td>81</td>\n",
       "      <td>Epicentre</td>\n",
       "      <td>epicentre paris</td>\n",
       "      <td>epicentre</td>\n",
       "      <td>Epicentre  Paris</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fondation Raoul Follereau</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>69</td>\n",
       "      <td>Fondation Raoul Follereau</td>\n",
       "      <td>fondation raoul follereau</td>\n",
       "      <td>fondation raoul follereau</td>\n",
       "      <td>Fondation Raoul Follereau</td>\n",
       "      <td>FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Institute for Health &amp; the Environment</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>68</td>\n",
       "      <td>Institute for Health &amp; the Environment</td>\n",
       "      <td>institute health environment</td>\n",
       "      <td>institute health environment</td>\n",
       "      <td>Institute for Health   the Environment</td>\n",
       "      <td>UNITED STATES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raymond M. Alf Museum of Paleontology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>67</td>\n",
       "      <td>Raymond M. Alf Museum of Paleontology</td>\n",
       "      <td>raymond alf museum paleontology</td>\n",
       "      <td>raymond alf museum paleontology</td>\n",
       "      <td>Raymond M  Alf Museum of Paleontology</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140353</th>\n",
       "      <td>“Victor Babes” University of Medicine and Phar...</td>\n",
       "      <td>Romania</td>\n",
       "      <td>1</td>\n",
       "      <td>“Victor Babes” University of Medicine and Phar...</td>\n",
       "      <td>victor babes university medicine pharmacy dept...</td>\n",
       "      <td>victor babes university medicine pharmacy</td>\n",
       "      <td>Victor Babes  University of Medicine and Phar...</td>\n",
       "      <td>Romania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140354</th>\n",
       "      <td>“Victor Babes” University of Medicine and Phar...</td>\n",
       "      <td>Romania</td>\n",
       "      <td>1</td>\n",
       "      <td>“Victor Babes” University of Medicine and Phar...</td>\n",
       "      <td>victor babes university medicine pharmacy dept...</td>\n",
       "      <td>victor babes university medicine pharmacy</td>\n",
       "      <td>Victor Babes  University of Medicine and Phar...</td>\n",
       "      <td>Romania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140355</th>\n",
       "      <td>“Vittorio Emanuele” Hospital, Liver Unit, Catania</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>“Vittorio Emanuele” Hospital</td>\n",
       "      <td>vittorio emanuele hospital liver unit catania</td>\n",
       "      <td>vittorio emanuele hospital</td>\n",
       "      <td>Vittorio Emanuele  Hospital  Liver Unit  Catania</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140356</th>\n",
       "      <td>”Dante Pazzanese” Institute of Cardiology, Sao...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1</td>\n",
       "      <td>”Dante Pazzanese” Institute of Cardiology</td>\n",
       "      <td>dante pazzanese institute cardiology sao paulo...</td>\n",
       "      <td>dante pazzanese institute cardiology</td>\n",
       "      <td>Dante Pazzanese  Institute of Cardiology  Sao...</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140357</th>\n",
       "      <td>”Victor Babes” National Institute of Pathology...</td>\n",
       "      <td>Romania</td>\n",
       "      <td>1</td>\n",
       "      <td>”Victor Babes” National Institute of Pathology</td>\n",
       "      <td>victor babes national institute pathology buch...</td>\n",
       "      <td>victor babes national institute pathology</td>\n",
       "      <td>Victor Babes  National Institute of Pathology...</td>\n",
       "      <td>Romania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140358 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     inst  ...          country_no_punct\n",
       "0       Freelance Science Writer, Sherborn, Massachusetts  ...  United States of America\n",
       "1                                        Epicentre, Paris  ...                    France\n",
       "2                               Fondation Raoul Follereau  ...                    FRANCE\n",
       "3                  Institute for Health & the Environment  ...             UNITED STATES\n",
       "4                   Raymond M. Alf Museum of Paleontology  ...  United States of America\n",
       "...                                                   ...  ...                       ...\n",
       "140353  “Victor Babes” University of Medicine and Phar...  ...                   Romania\n",
       "140354  “Victor Babes” University of Medicine and Phar...  ...                   Romania\n",
       "140355  “Vittorio Emanuele” Hospital, Liver Unit, Catania  ...                     Italy\n",
       "140356  ”Dante Pazzanese” Institute of Cardiology, Sao...  ...                    Brazil\n",
       "140357  ”Victor Babes” National Institute of Pathology...  ...                   Romania\n",
       "\n",
       "[140358 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    " ## Before using Dimensions: Remove instances on em and solr that already exist on main_insts\n",
    "     # If the inst names are already there, no need to look up with country and/or city\n",
    " ## NOTE: You can use this after Dimensions & fuzzy matching too: It cleans the em and solr data from existing main_insts insts.\n",
    "##################################################\n",
    "solr_insts = pd.merge(solr_insts, main_insts, how='left', on = 'inst')\n",
    "solr_insts = solr_insts[solr_insts['grid_id'].isnull()].drop('grid_id', axis = 1).reset_index(drop=True)\n",
    "em_insts = pd.merge(em_insts, main_insts, how='left', left_on= 'Institute', right_on = 'inst')\n",
    "em_insts = em_insts[em_insts['grid_id'].isnull()].drop(['inst', 'grid_id'], axis = 1).reset_index(drop=True)\n",
    "solr_insts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gaMAUlDhQhPk",
    "outputId": "997644f5-6617-477d-d476-48301260140b"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    " ## Use Dimensions’ extract_affiliation method on (a) raw Solar name (b) Solar name after comma separated method\n",
    "##################################################\n",
    "###############\n",
    " ### Jarrett log on to Dimensions: REDACTED\n",
    "###############\n",
    "username = # *** REDACTED ***\n",
    "password = # *** REDACTED ***\n",
    "endpoint = \"https://app.dimensions.ai\"\n",
    "\n",
    "###############\n",
    " ### Need to install at beginning of each session:\n",
    "###############\n",
    "!pip install dimcli\n",
    "\n",
    "###############\n",
    " ### Easy sample query with iterations to get full results:\n",
    "###############\n",
    "import dimcli\n",
    "dimcli.login(username, password, endpoint)\n",
    "dsl = dimcli.Dsl()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    " ## Method to use Dimensions' extract_affiliation() with a 199 batch with solr & EM:\n",
    "   # Use solr's inst & connect_inst; use EM's Institute & connect_inst (split inst is too risky).\n",
    "##################################################\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def dimensions_batch(unclean_data, merged_inst_name, raw_inst_name):\n",
    "    ### NOTE: I use batches of length 199 for dimensions: https://docs.dimensions.ai/dsl/functions.html#function-extract-affiliations\n",
    "    count = 0\n",
    "    final_data = pd.DataFrame(columns = ['inst', 'grid_id'])\n",
    "    for i in range(int(len(unclean_data)/199)-1):\n",
    "        temp_batch = ','.join(unclean_data[merged_inst_name][count:(count+199)])\n",
    "        data = dsl.query(f\"\"\"extract_affiliations(json=[{temp_batch}])\"\"\")\n",
    "        temp_data = []\n",
    "        for j in range(199):\n",
    "        ### If there is a result for institution put in grid_id, if not put in 'NaN' (need for symmetry with inital dataset):\n",
    "            if len(data.json['results'][j]['matches'][0]['institutes']) > 0:\n",
    "                temp_data.append(json.dumps(data['results'][j]['matches'][0]['institutes'][0]['institute']['id'])[1:-1])\n",
    "            else:\n",
    "                temp_data.append(np.nan)\n",
    "        temp_dataframe = pd.DataFrame({'inst': list(unclean_data[raw_inst_name][count:(count+199)]), 'grid_id': temp_data})\n",
    "        final_data = pd.concat([final_data, temp_dataframe], ignore_index=True)\n",
    "        time.sleep(2.05)\n",
    "        count += 199\n",
    "    return final_data\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    " ## Use the dimensions_batch() function on each data/var combination:\n",
    "   # Use on solr's inst & connect_inst; use EM's Institute, connect_inst and Affiliation\n",
    "   # Take out punctuation and merge variables into pre-combined json format.\n",
    "##################################################\n",
    "###############\n",
    " ### Use dimensions_batch() on Solr's inst\n",
    "###############\n",
    "### Create 'merged' field with no punctuations and use the dimensions_batch function\n",
    "#solr_insts = solr_insts[solr_insts['inst'].notnull()].reset_index(drop=True)  # remove nas from inst (produces errors in .join)\n",
    "#solr_insts['inst_no_punct'] = solr_insts['inst'].str.replace('[^\\w\\s]',' ')\n",
    "#solr_insts['country_no_punct'] = solr_insts['country'].str.replace('[^\\w\\s]',' ')\n",
    "#solr_insts['merged'] = '{\"affiliation\":' + ' \"' + solr_insts['inst_no_punct'] + \" \" + solr_insts['country_no_punct'] + '\"}'\n",
    "##solr_insts_2 = solr_insts.iloc[0:400,:].reset_index(drop=True)   ## For a smaller sample, add '_2' to end of next row's 1st entry\n",
    "#cleaned_solr_inst = dimensions_batch(solr_insts, \"merged\", \"inst\")\n",
    "### Connect matches to main_insts:\n",
    "#new_connects = cleaned_solr_inst[cleaned_solr_inst['grid_id'].notnull()]\n",
    "#main_insts = pd.concat([main_insts, new_connects], ignore_index=True)\n",
    "#main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "### Remove matches from solr_insts:\n",
    "#new_connects = new_connects.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "#solr_insts = pd.merge(solr_insts, new_connects, how='left', on = 'inst')\n",
    "#solr_insts = solr_insts[solr_insts['grid_id'].isnull()].drop('grid_id', axis = 1).reset_index(drop=True)\n",
    "\n",
    "###############\n",
    " ### Use dimensions_batch() on Solr's connect_inst (cleaned insts):\n",
    "###############\n",
    "### Create 'merged' field with clean data and use the dimensions_batch function\n",
    "#solr_insts['country_no_punct'] = solr_insts['country'].str.replace('[^\\w\\s]',' ')\n",
    "#solr_insts['merged'] = '{\"affiliation\":' + ' \"' + solr_insts['connect_inst'] + \" \" + solr_insts['country_no_punct'] + '\"}'\n",
    "##solr_insts_2 = solr_insts.iloc[0:400,:].reset_index(drop=True)   ## For a smaller sample, add '_2' to end of next row's 1st entry\n",
    "#cleaned_solr_connect_inst = dimensions_batch(solr_insts, \"merged\", \"inst\")\n",
    "### Connect matches to main_insts:\n",
    "#new_connects = cleaned_solr_connect_inst[cleaned_solr_connect_inst['grid_id'].notnull()]\n",
    "#main_insts = pd.concat([main_insts, new_connects], ignore_index=True)\n",
    "#main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "### Remove matches from solr_insts:\n",
    "#new_connects = new_connects.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "#solr_insts = pd.merge(solr_insts, new_connects, how='left', on = 'inst')\n",
    "#solr_insts = solr_insts[solr_insts['grid_id'].isnull()].drop('grid_id', axis = 1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "###############\n",
    " ### Use dimensions_batch() on Use dimensions_batch() on EM's Institute:\n",
    "   # Need to change Country and City for Em data since there's many N/A's\n",
    "###############\n",
    "### Create 'merged' field where Country and City NAs = \"\", with no punctuations in inst city or country, and use the dimensions_batch function\n",
    "#em_insts = em_insts[em_insts['Institute'].notnull()].reset_index(drop=True)\n",
    "#temp_em_insts = em_insts.fillna(\"\")\n",
    "#temp_em_insts.loc[temp_em_insts.Country == \"N\\A\", 'Country'] = \"\"\n",
    "#temp_em_insts.loc[temp_em_insts.City == \"N\\A\", 'City'] = \"\"\n",
    "#emp_em_insts['inst_no_punct'] = temp_em_insts['Institute'].str.replace('[^\\w\\s]',' ')\n",
    "#temp_em_insts['Country'] = temp_em_insts['Country'].str.replace('[^\\w\\s]',' ')\n",
    "#temp_em_insts['City'] = temp_em_insts['City'].str.replace('[^\\w\\s]',' ')\n",
    "#temp_em_insts['no_duplicates'] = temp_em_insts['inst_no_punct'] + temp_em_insts['Country'] + temp_em_insts['City']\n",
    "#temp_em_insts = temp_em_insts.drop_duplicates(subset=['no_duplicates'], keep = 'first').reset_index(drop = True)\n",
    "### Create 'merged' field with clean data and use the dimensions_batch function\n",
    "#temp_em_insts['merged'] = '{\"affiliation\":' + ' \"' + temp_em_insts['inst_no_punct'] + \" \" + temp_em_insts['Country'] + \" \" + temp_em_insts['City'] + '\"}'\n",
    "##temp_em_insts_2 = temp_em_insts.iloc[0:600,:].reset_index(drop=True)   ## For a smaller sample, add '_2' to end of next row's 1st entry\n",
    "#cleaned_em_inst = dimensions_batch(temp_em_insts, \"merged\", \"Institute\")\n",
    "### Connect matches to main_insts:\n",
    "#new_connects = cleaned_em_inst[cleaned_em_inst['grid_id'].notnull()]\n",
    "#main_insts = pd.concat([main_insts, new_connects], ignore_index=True)\n",
    "#main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "### Remove matches from em_insts:\n",
    "#new_connects = new_connects.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "#em_insts = pd.merge(em_insts, new_connects, how='left', left_on= 'Institute', right_on = 'inst')\n",
    "#em_insts = em_insts[em_insts['grid_id'].isnull()].drop(['inst', 'grid_id'], axis = 1).reset_index(drop=True)\n",
    "\n",
    "###############\n",
    " ### Use dimensions_batch() on EM's connect_inst (cleaned insts):\n",
    "###############\n",
    "### Create 'merged' field where Country and City NAs = \"\", with no punctuations in city or country, and use the dimensions_batch function\n",
    "#em_insts = em_insts[em_insts['Institute'].notnull()].reset_index(drop=True)\n",
    "#temp_em_insts = em_insts.fillna(\"\")\n",
    "#temp_em_insts.loc[temp_em_insts.Country == \"N\\A\", 'Country'] = \"\"\n",
    "#temp_em_insts.loc[temp_em_insts.City == \"N\\A\", 'City'] = \"\"\n",
    "#temp_em_insts['Country'] = temp_em_insts['Country'].str.replace('[^\\w\\s]',' ')\n",
    "#temp_em_insts['City'] = temp_em_insts['City'].str.replace('[^\\w\\s]',' ')\n",
    "#temp_em_insts['no_duplicates'] = temp_em_insts['connect_inst'] + temp_em_insts['Country'] + temp_em_insts['City']\n",
    "#temp_em_insts = temp_em_insts.drop_duplicates(subset=['no_duplicates'], keep = 'first').reset_index(drop = True)\n",
    "### Create 'merged' field with clean data and use the dimensions_batch function\n",
    "#temp_em_insts['merged'] = '{\"affiliation\":' + ' \"' + temp_em_insts['connect_inst'] + \" \" + temp_em_insts['Country'] + \" \" + temp_em_insts['City'] + '\"}'\n",
    "#temp_em_insts = temp_em_insts.iloc[0:600,:].reset_index(drop=True)   ## For a smaller sample, add '_2' to end of next row's 1st entry\n",
    "#cleaned_em_connect_inst = dimensions_batch(temp_em_insts, \"merged\", \"Institute\")\n",
    "### Connect matches to main_insts:\n",
    "#new_connects = cleaned_em_connect_inst[cleaned_em_connect_inst['grid_id'].notnull()]\n",
    "#main_insts = pd.concat([main_insts, new_connects], ignore_index=True)\n",
    "#main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "### Remove matches from em_insts:\n",
    "#new_connects = new_connects.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "#em_insts = pd.merge(em_insts, new_connects, how='left', left_on= 'Institute', right_on = 'inst')\n",
    "#em_insts = em_insts[em_insts['grid_id'].isnull()].drop(['inst', 'grid_id'], axis = 1).reset_index(drop=True)\n",
    "\n",
    "###############\n",
    " ### Use dimensions_batch() on Use dimensions_batch() on EM's clean_affiliation (cleaned affiliations):\n",
    "###############\n",
    "### Create 'merged' field where Country and City NAs = \"\", with no punctuations in city or country, and use the dimensions_batch function\n",
    "temp_em_insts = em_insts[em_insts['connect_affiliation'].notnull()].reset_index(drop=True)\n",
    "temp_em_insts = em_insts.fillna(\"\")\n",
    "temp_em_insts.loc[temp_em_insts.Country == \"N\\A\", 'Country'] = \"\"\n",
    "temp_em_insts.loc[temp_em_insts.City == \"N\\A\", 'City'] = \"\"\n",
    "temp_em_insts['Country'] = temp_em_insts['Country'].str.replace('[^\\w\\s]',' ')\n",
    "temp_em_insts['City'] = temp_em_insts['City'].str.replace('[^\\w\\s]',' ')\n",
    "temp_em_insts['no_duplicates'] = temp_em_insts['connect_affiliation'] + temp_em_insts['Country'] + temp_em_insts['City']\n",
    "temp_em_insts = temp_em_insts.drop_duplicates(subset=['no_duplicates'], keep = 'first').reset_index(drop = True)\n",
    "### Create 'merged' field with clean data and use the dimensions_batch function\n",
    "temp_em_insts['merged'] = '{\"affiliation\":' + ' \"' + temp_em_insts['connect_affiliation'] + \" \" + temp_em_insts['Country'] + \" \" + temp_em_insts['City'] + '\"}'\n",
    "#temp_em_insts = temp_em_insts.iloc[0:600,:].reset_index(drop=True)   ## For a smaller sample, add '_2' to end of next row's 1st entry\n",
    "cleaned_em_connect_aff = dimensions_batch(temp_em_insts, \"merged\", \"Affiliation\")\n",
    "### Connect matches to main_insts:\n",
    "new_connects = cleaned_em_connect_aff[cleaned_em_connect_aff['grid_id'].notnull()]\n",
    "main_insts = pd.concat([main_insts, new_connects], ignore_index=True)\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8_IN0oHoN8i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKOQZrf77KGl"
   },
   "source": [
    "# Email domain to GRID link matching: over 50 instances of an institute by email domain in EM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "1XMZ85OxqJN1",
    "outputId": "a8726f94-9f62-46b0-ba38-a21c9171bf87"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    " ## Use domain matching on domains with over 50 instances of 'connect_inst' for em_insts\n",
    "##################################################\n",
    "###############\n",
    " ### Make the domain connectors for EM (1st email only) and GRID data. Then connect grid's ID onto em_insts\n",
    "###############\n",
    "### Create 'domain_connect'\n",
    "em_insts['domain_connect'] = em_insts['Email'].str.split(\";\",1).str[0]\n",
    "em_insts['domain_connect'] = em_insts['domain_connect'].str.split(\"@\",1).str[1]\n",
    "temp_grid = grid_insts[grid_insts['type'] == \"Education\"]\n",
    "temp_grid['domain_connect'] = temp_grid['link'].str.split(\"www.\",1).str[1].str[:-1]\n",
    "temp_grid = temp_grid[['domain_connect', 'ID']].dropna().drop_duplicates(subset=['domain_connect'], keep = False)\n",
    "em_insts = pd.merge(em_insts, temp_grid, how='left', on=['domain_connect'])\n",
    "\n",
    "###############\n",
    " ### Create a temp dataset, de-duplicating by email domain.\n",
    "###############\n",
    "temp_domain_data = em_insts.drop_duplicates(subset=['Email'], keep = 'first')\n",
    "temp_domain_data['concat'] = temp_domain_data['domain_connect'] + temp_domain_data['connect_inst']\n",
    "\n",
    "###############\n",
    " ### Find and limit temp dataset to institute by domain connections with over 100 unique email instances:\n",
    "###############\n",
    "import nltk\n",
    "dom_agg = nltk.FreqDist(temp_domain_data['concat'])\n",
    "dom_agg = dict((k, v) for k, v in dom_agg.items() if v > 49)              ######################### JUST CHANGE THIS '49' TO GO LOWER.\n",
    "dom_list = list(dom_agg.keys())\n",
    "temp_domain_data = temp_domain_data[temp_domain_data['concat'].isin(dom_list)]\n",
    "\n",
    "###############\n",
    " ### Put inst - domain connections onto main_insts\n",
    "###############\n",
    "to_main_data = temp_domain_data[['Institute', 'ID']]\n",
    "to_main_data = to_main_data[to_main_data['ID'].notnull()]\n",
    "to_main_data.columns = ['inst', 'grid_id']\n",
    "main_insts = pd.concat([main_insts,to_main_data], ignore_index=True)\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "\n",
    "###############\n",
    " ### Remove inst - domain connections from EM:\n",
    "###############\n",
    "em_insts = em_insts[~em_insts['Institute'].isin(to_main_data['inst'])].reset_index(drop = True).drop('ID', axis=1)\n",
    "\n",
    "\n",
    "em_insts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VjSnJpv7k5H"
   },
   "source": [
    "# Use fuzzy matching (with KNN) to connect EM & Solr to GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "id": "tC9faabpI8Ch",
    "outputId": "ba2e6a1c-0e94-4508-fde3-866ecbdd3f34"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "  ## Fast fuzzy matching\n",
    "    # NOTE: Found a way quicker way than fuzzywuzzy to do fuzzy matching here: https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536\n",
    "        # Calculates tf-idfs on words & bi-grams of GRID insts, then uses k nearest neighborhors to calculate similarity.\n",
    "    # NOTE: Using clean institutions got a little weird so I'm only use the non-clean inst names.\n",
    "    ### Based on some research/tests, it looks like Solr is good using a match under .76. em insts is *much* murkier and should only use under .41\n",
    "##################################################\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def kneighbors_fuzzy_match(unclean_list, clean_list, grid_id_connect):\n",
    "    vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1, 2), lowercase=False)\n",
    "    tfidf = vectorizer.fit_transform(clean_list)\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "    ### Matching query:\n",
    "    def getNearestN(query):\n",
    "        queryTFIDF_ = vectorizer.transform(query)\n",
    "        distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "        return distances, indices\n",
    "    distances, indices = getNearestN(unclean_list)\n",
    "    unique_org = list(unclean_list) #need to convert back to a list\n",
    "    matches = []\n",
    "    for i,j in enumerate(indices):\n",
    "        temp = [round(distances[i][0],2), clean_list.values[j][0], unique_org[i], str(grid_id_connect[j]).split(' ')[4][:-6]]\n",
    "        matches.append(temp)\n",
    "    matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name (clean)','inst', 'grid_id'])\n",
    "    matches = matches.sort_values('Match confidence (lower is better)')\n",
    "    return matches\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "  ## Use the kneighbors_fuzzy_match() method, then add to main_insts and remove from solr or EM\n",
    "     ## Do the following: solr's inst, clean_inst, then split_inst ... and EM's Institute, clean_inst, then clean_affiliation.\n",
    "     ## NOTE: NEED TO DEFINE WHAT IS A HIGH CONFIDENCE MATCH BEFORE PUTTING INTO MAIN DATA (currently using under .76)\n",
    "##################################################\n",
    "###############\n",
    " ### Define grid insts to use (unclean and clean)\n",
    "###############\n",
    "temp_grid = grid_insts[['Name', 'ID']].drop_duplicates(subset=['Name'], keep = False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "###############\n",
    " ### fuzzy match unclean solr insts:\n",
    "###############\n",
    "#### Use kneighbors_fuzzy_match() to get fuzzy matches\n",
    "solr_insts_2 = list(set(list(solr_insts['inst'])))\n",
    "solr_fuzzy_connect = kneighbors_fuzzy_match(solr_insts_2, temp_grid['Name'], temp_grid['ID'])\n",
    "#### Connect matches to main_insts:\n",
    "new_connects = solr_fuzzy_connect[(solr_fuzzy_connect['Match confidence (lower is better)'] < 0.76) & (solr_fuzzy_connect['Match confidence (lower is better)'] > 0) & (solr_fuzzy_connect['inst'] != \"\")]\n",
    "new_connects = new_connects[['inst', 'grid_id']].drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "main_insts = pd.concat([main_insts, new_connects], ignore_index=True)\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "#### Remove matches from solr_insts:\n",
    "solr_insts = pd.merge(solr_insts, new_connects, how='left', on = 'inst')\n",
    "solr_insts = solr_insts[solr_insts['grid_id'].isnull()].drop('grid_id', axis = 1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "###############\n",
    " ### fuzzy match unclean em insts:\n",
    "###############\n",
    "#### Use kneighbors_fuzzy_match() to get fuzzy matches\n",
    "em_insts_2 = em_insts.drop_duplicates(subset=['Institute'], keep = 'first').reset_index(drop = True)\n",
    "em_insts_2 = em_insts_2['Institute']\n",
    "em_fuzzy_connect = kneighbors_fuzzy_match(em_insts_2, temp_grid['Name'], temp_grid['ID'])\n",
    "#### Connect matches to main_insts:\n",
    "new_connects = em_fuzzy_connect[(em_fuzzy_connect['Match confidence (lower is better)'] < 0.41) & (em_fuzzy_connect['Match confidence (lower is better)'] > 0) & (em_fuzzy_connect['inst'] != \"\")]\n",
    "new_connects = new_connects[['inst', 'grid_id']].drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "main_insts = pd.concat([main_insts, new_connects], ignore_index=True)\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "#### Remove matches from em_insts:\n",
    "em_insts = pd.merge(em_insts, new_connects, how='left', left_on= 'Institute', right_on = 'inst')\n",
    "em_insts = em_insts[em_insts['grid_id'].isnull()].drop('grid_id', 'inst', axis = 1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "em_insts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8jasoKP_hw4"
   },
   "source": [
    "# By hand connecting unconnected rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "OMa9jp5fedLm",
    "outputId": "ec0c0706-7710-489f-cc51-6915eb640440"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst</th>\n",
       "      <th>grid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Chinese Academy of Sciences, Bei...</td>\n",
       "      <td>grid.410726.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Basel, Basel</td>\n",
       "      <td>grid.6612.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harvard Medical School, Boston, Massachusetts</td>\n",
       "      <td>grid.471403.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Swiss Tropical and Public Health Institute, Basel</td>\n",
       "      <td>grid.416786.a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fogarty International Center, National Institu...</td>\n",
       "      <td>grid.453035.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660985</th>\n",
       "      <td>IBMB-CSIC</td>\n",
       "      <td>grid.428973.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660986</th>\n",
       "      <td>Wageningen Bioveterinary Research</td>\n",
       "      <td>grid.4818.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660987</th>\n",
       "      <td>Akademia Wychowania Fizycznego imienia Jerzego...</td>\n",
       "      <td>grid.445174.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660988</th>\n",
       "      <td>UMKC</td>\n",
       "      <td>grid.266756.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660989</th>\n",
       "      <td>Hualien Tzu Chi Hospital</td>\n",
       "      <td>grid.464578.c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660990 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     inst        grid_id\n",
       "0       University of Chinese Academy of Sciences, Bei...  grid.410726.6\n",
       "1                              University of Basel, Basel    grid.6612.3\n",
       "2           Harvard Medical School, Boston, Massachusetts  grid.471403.5\n",
       "3       Swiss Tropical and Public Health Institute, Basel  grid.416786.a\n",
       "4       Fogarty International Center, National Institu...  grid.453035.4\n",
       "...                                                   ...            ...\n",
       "660985                                          IBMB-CSIC  grid.428973.3\n",
       "660986                  Wageningen Bioveterinary Research    grid.4818.5\n",
       "660987  Akademia Wychowania Fizycznego imienia Jerzego...  grid.445174.7\n",
       "660988                                               UMKC  grid.266756.6\n",
       "660989                           Hualien Tzu Chi Hospital  grid.464578.c\n",
       "\n",
       "[660990 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "  ## By hand connections for top unconnected solr_insts\n",
    "##################################################\n",
    "###############\n",
    " ### Found the GRIDs (for those that could actually be connected) for the top 25. Attach to final lookup list:\n",
    "###############\n",
    "#solr_insts.iloc[0:25]\n",
    "#solr_add_ons = pd.DataFrame([['DOE Pacific Northwest National Laboratory', 'grid.451303.0'], [\"Charité, Campus Benjamin Franklin\", 'grid.6363.0'], ['Department of Molecular Genetics and Microbiology, Duke University Medical Center, Durham, North Carolina', 'grid.414179.e'], ['Department of Biological Engineering, Massachusetts Institute of Technology, Cambridge, Massachusetts', 'grid.116068.8'], ['Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, Washington', 'grid.270240.3'], ['Department of Pathology, University of Texas Medical Branch, Galveston, Texas', 'grid.176731.5'], ['Management Office for Health Data, China Medical University Hospital, Taichung', 'grid.411508.9'], ['Department of Molecular and Cellular Biology, Baylor College of Medicine, Houston, Texas', 'grid.39382.33'], ['Department of Pediatrics, Baylor College of Medicine, Houston, Texas, Houston, Texas', 'grid.39382.33'], ['Sanjay Gandhi Medical Institute', 'grid.263138.d'], ['Department of Infectious Disease Epidemiology, London School of Hygiene and Tropical Medicine, London', 'grid.8991.9'], ['Faculty of Epidemiology and Population Health, London School of Hygiene and Tropical Medicine, London', 'grid.8991.9'], ['Department of Molecular Virology and Microbiology, Baylor College of Medicine, Houston, Texas', 'grid.39382.33'], [\"Institut d'Investigacions Biomediques de Barcelona\", 'grid.420258.9'], [\"IRCCS E. Medea\", 'grid.420417.4'], [\"Institute of Epidemiology and Preventive Medicine, College of Public Health, National Taiwan University, Taipei\", 'grid.19188.39'], [\"Duke Global Health Institute, Duke University, Durham, North Carolina\", 'grid.26009.3d'], ['Department of Neuroscience, Baylor College of Medicine, Houston, Texas', 'grid.39382.33'], [\"Department of Global Health and Social Medicine, Harvard Medical School, Boston, Massachusetts\", 'grid.471403.5']], columns = ['inst', 'grid_id'])\n",
    "#main_insts = pd.concat([main_insts, solr_add_ons], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "  ## By hand connections for top unconnected em_insts\n",
    "##################################################\n",
    "###############\n",
    " ### Get the frequency of unconnected em_insts (solr already has counts). Attach to final lookup list:\n",
    "###############\n",
    "#import nltk\n",
    "#em_insts['Inst_by_country'] = em_insts['Institute'] + \" : \" + em_insts['Country']\n",
    "#em_count = nltk.FreqDist(em_insts['Inst_by_country'])\n",
    "#em_count = dict((k, v) for k, v in em_count.items() if v > 50)\n",
    "#em_count = sorted(em_count.items(), key=lambda x: x[1], reverse = True)\n",
    "#em_count\n",
    "\n",
    "\n",
    "###############\n",
    " ### Find GRIDs for unconnected over 50\n",
    "###############\n",
    "em_add_ons = pd.DataFrame([[\"FHI 360\", \"grid.245835.d\"], [\"INMI Lazzaro Spallanzani IRCCS\", \"grid.419423.9\"], [\"INRA Centre Val de Loire\", \"grid.418065.e\"], [\"Uniwersytet Warminsko-Mazurski\", \"grid.412607.6\"], [\"Shandong Qianfoshan Hospital\", \"grid.452422.7\"], [\"INRAE\", \"grid.507621.7\"], [\"Guangzhou Military General Hospital\", \"grid.413435.4\"], [\"Ahvaz Jondishapour University of Medical Sciences\", \"grid.411230.5\"], [\"Wageningen UR\", \"grid.4818.5\"], [\"Guangdong Hospital of Traditional Chinese Medicine\", \"grid.413402.0\"], [\"Changzhou First People's Hospital\", \"grid.490563.d\"], [\"College of Medicine, Korea University\", \"grid.222754.4\"], [\"Hellenic Center for Marine Research\", \"grid.410335.0\"], [\"INRA Centre de Bordeaux-Aquitaine\", \"grid.462308.b\"], [\"Biologicke centrum Akademie Ved Ceske Republiky\", \"grid.418338.5\"], [\"Children's Hospital of Shanghai\", \"grid.415625.1\"], [\"U.S. Fish and Wildlife Service\", \"grid.245835.d\"], [\"MRC/UVRI and LSHTM Uganda Research Unit\", \"grid.415861.f\"], [\"Zibo Central Hospital\", \"grid.477019.c\"], [\"GHESKIO\", \"grid.456968.0\"], [\"Azienda Socio Sanitaria Territoriale Grande Ospedale Metropolitano Niguarda\", \"grid.416200.1\"], [\"Rumah Sakit Dr Cipto Mangunkusumo\", \"grid.487294.4\"], [\"KEMRI/CDC\", \"grid.33058.3d\"], [\"Azienda Socio Sanitaria Territoriale degli Spedali Civili di Brescia\", \"grid.412725.7\"], [\"ICRISAT\", \"grid.419337.b\"], [\"Galilee Medical Center\", \"grid.415839.2\"], [\"IBMB-CSIC\", \"grid.428973.3\"], [\"Wageningen Bioveterinary Research\", \"grid.4818.5\"], [\"Akademia Wychowania Fizycznego imienia Jerzego Kukuczki w Katowicach\", \"grid.445174.7\"], [\"UMKC\", \"grid.266756.6\"], [\"Hualien Tzu Chi Hospital\", \"grid.464578.c\"]], columns = ['inst', 'grid_id'])\n",
    "main_insts = pd.concat([main_insts, em_add_ons], ignore_index=True)\n",
    "main_insts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1lwzqrg_rKU"
   },
   "source": [
    "# By-hand removal of common insts on main_insts that shouldn't be there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "vbMy4KnrAJzn",
    "outputId": "55d13c9b-3a16-443d-8138-426df8d3c996"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst</th>\n",
       "      <th>grid_id</th>\n",
       "      <th>merging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Chinese Academy of Sciences, Bei...</td>\n",
       "      <td>grid.410726.6</td>\n",
       "      <td>University of Chinese Academy of Sciences, Bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Basel, Basel</td>\n",
       "      <td>grid.6612.3</td>\n",
       "      <td>University of Basel, Basel : grid.6612.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harvard Medical School, Boston, Massachusetts</td>\n",
       "      <td>grid.471403.5</td>\n",
       "      <td>Harvard Medical School, Boston, Massachusetts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Swiss Tropical and Public Health Institute, Basel</td>\n",
       "      <td>grid.416786.a</td>\n",
       "      <td>Swiss Tropical and Public Health Institute, Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fogarty International Center, National Institu...</td>\n",
       "      <td>grid.453035.4</td>\n",
       "      <td>Fogarty International Center, National Institu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655440</th>\n",
       "      <td>IBMB-CSIC</td>\n",
       "      <td>grid.428973.3</td>\n",
       "      <td>IBMB-CSIC : grid.428973.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655441</th>\n",
       "      <td>Wageningen Bioveterinary Research</td>\n",
       "      <td>grid.4818.5</td>\n",
       "      <td>Wageningen Bioveterinary Research : grid.4818.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655442</th>\n",
       "      <td>Akademia Wychowania Fizycznego imienia Jerzego...</td>\n",
       "      <td>grid.445174.7</td>\n",
       "      <td>Akademia Wychowania Fizycznego imienia Jerzego...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655443</th>\n",
       "      <td>UMKC</td>\n",
       "      <td>grid.266756.6</td>\n",
       "      <td>UMKC : grid.266756.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655444</th>\n",
       "      <td>Hualien Tzu Chi Hospital</td>\n",
       "      <td>grid.464578.c</td>\n",
       "      <td>Hualien Tzu Chi Hospital : grid.464578.c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>655445 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     inst  ...                                            merging\n",
       "0       University of Chinese Academy of Sciences, Bei...  ...  University of Chinese Academy of Sciences, Bei...\n",
       "1                              University of Basel, Basel  ...           University of Basel, Basel : grid.6612.3\n",
       "2           Harvard Medical School, Boston, Massachusetts  ...  Harvard Medical School, Boston, Massachusetts ...\n",
       "3       Swiss Tropical and Public Health Institute, Basel  ...  Swiss Tropical and Public Health Institute, Ba...\n",
       "4       Fogarty International Center, National Institu...  ...  Fogarty International Center, National Institu...\n",
       "...                                                   ...  ...                                                ...\n",
       "655440                                          IBMB-CSIC  ...                          IBMB-CSIC : grid.428973.3\n",
       "655441                  Wageningen Bioveterinary Research  ...    Wageningen Bioveterinary Research : grid.4818.5\n",
       "655442  Akademia Wychowania Fizycznego imienia Jerzego...  ...  Akademia Wychowania Fizycznego imienia Jerzego...\n",
       "655443                                               UMKC  ...                               UMKC : grid.266756.6\n",
       "655444                           Hualien Tzu Chi Hospital  ...           Hualien Tzu Chi Hospital : grid.464578.c\n",
       "\n",
       "[655445 rows x 3 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "  ## By-hand removal of common insts on main_insts\n",
    "##################################################\n",
    "###############\n",
    " ### There was one empty inst, so remove. Also de-dup and remove where inst is only numbers:\n",
    "###############\n",
    "main_insts = main_insts[main_insts['inst'].notnull()]\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "main_insts = main_insts[~main_insts['inst'].str.isnumeric()].reset_index(drop = True)\n",
    "\n",
    "###############\n",
    " ### Remove where the character len of inst is '2 or under' or 'over 425'\n",
    "###############\n",
    "main_insts['char_len'] = main_insts['inst'].str.len()\n",
    "main_insts = main_insts[(main_insts['char_len'] > 2) & (main_insts['char_len'] < 425)].drop('char_len', axis=1).reset_index(drop = True)\n",
    "\n",
    "###############\n",
    " ### Common non-'Education' GRID connections (over 90 rows in main_insts) that should be excluded from main_insts list: \n",
    "###############\n",
    "#import nltk\n",
    "#counts = nltk.FreqDist(main_insts['grid_id'])\n",
    "#counts = dict((k, v) for k, v in counts.items() if v > 20)\n",
    "#counts = sorted(counts.items(), key=lambda x: x[1], reverse = True)\n",
    "#counts = pd.merge(pd.DataFrame(counts), grid_insts, how='left', left_on= 0, right_on = 'ID')\n",
    "#counts = counts[[0,1,\"Name\"]]\n",
    "#counts\n",
    "##### Look at the name variations for a particular grid:\n",
    "#main_insts[main_insts['grid_id'] == 'XXXXXXXXXX']\n",
    "\n",
    "###############\n",
    " ### Common non-'Education' GRID connections (over 90 rows in main_insts) that should be excluded from main_insts list: \n",
    "###############\n",
    "grid_ids_to_remove = [\"grid.466117.3\", \"grid.462718.e\", \"grid.449710.f\", \"grid.495658.3\", \"grid.426602.4\", \"grid.418761.d\", \"grid.467642.5\", \"grid.466112.6\", \"grid.419475.a\", \"grid.414102.2\", \"grid.417768.b\", \"grid.462937.d\", \"grid.501573.5\", \"grid.414070.6\"]\n",
    "    # NOTE: These are the grid_ids to remove from main_insts (way too generic)\n",
    "      # These are their names: [\"Department of Biological Sciences\", \"Department of Virology\", \"University Hospital\", \"Institute of Biology\", \"Institute of Virology\", \"Institute of Immunology\", \"Center for Global Health\", \"Department of Mathematical Sciences\", \"National Institute on Aging\", \"Department of Health\", \"Center for Cancer Research\", \"Computer Science Department\", \"Department of Archaeology\", \"Children's Hospital\"]\n",
    "main_insts = main_insts[~main_insts['grid_id'].isin(grid_ids_to_remove)].reset_index(drop = True)\n",
    "\n",
    "###############\n",
    " ### Based on the look-up, remove rows where the grid_id starts with 'Department of'\n",
    "###############\n",
    "department_to_remove = grid_insts[grid_insts['Name'].str.startswith('Department of', na=False)]\n",
    "department_to_remove = list(department_to_remove[\"ID\"])\n",
    "main_insts = main_insts[~main_insts['grid_id'].isin(department_to_remove)].reset_index(drop = True)\n",
    "\n",
    "###############\n",
    " ### Download main_insts again:\n",
    "###############\n",
    "#from google.colab import files\n",
    "#main_insts.to_csv('main_insts.csv')\n",
    "#files.download('main_insts.csv')\n",
    "\n",
    "main_insts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QE0dkw12AyMU"
   },
   "source": [
    "# Use fuzzy matching (with KNN) to connect EM & Solr to main lookup table (main_insts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "99A8wWViAyYz",
    "outputId": "8f0d5709-19b7-4e1d-95f5-33cc42f5aaa5"
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "  ## Fuzzy matching solr & em on main_insts:\n",
    "    # NOTE: Do on solr & EM unclean insts.\n",
    "      # NOTE: Make the threshold stricter than the 1st go. Based on research: under .66 for solr and under .36 for em\n",
    "##################################################\n",
    "###############\n",
    " ### Fast fuzzy matching (same as above):\n",
    "###############\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "def kneighbors_fuzzy_match(unclean_list, clean_list, grid_id_connect):\n",
    "    vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1, 2), lowercase=False)\n",
    "    tfidf = vectorizer.fit_transform(clean_list)\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "    ### Matching query:\n",
    "    def getNearestN(query):\n",
    "        queryTFIDF_ = vectorizer.transform(query)\n",
    "        distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "        return distances, indices\n",
    "    distances, indices = getNearestN(unclean_list)\n",
    "    unique_org = list(unclean_list) #need to convert back to a list\n",
    "    matches = []\n",
    "    for i,j in enumerate(indices):\n",
    "        temp = [round(distances[i][0],2), clean_list.values[j][0], unique_org[i], str(grid_id_connect[j]).split(' ')[4][:-6]]\n",
    "        matches.append(temp)\n",
    "    matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name (clean)','inst', 'grid_id'])\n",
    "    matches = matches.sort_values('Match confidence (lower is better)')\n",
    "    return matches\n",
    "\n",
    "###############\n",
    " ### Fuzzy matching solr inst on the insts in main_insts:\n",
    "###############\n",
    "#### Use kneighbors_fuzzy_match() to get fuzzy matches\n",
    "#solr_insts_2 = list(set(list(solr_insts['inst'])))\n",
    "#solr_fuzzy_connect = kneighbors_fuzzy_match(solr_insts_2, main_insts['inst'], main_insts['grid_id'])\n",
    "#solr_fuzzy_connect\n",
    "#### Connect matches to main_insts:\n",
    "#new_connects = solr_fuzzy_connect[(solr_fuzzy_connect['Match confidence (lower is better)'] < 0.66) & (solr_fuzzy_connect['Match confidence (lower is better)'] > 0) & (solr_fuzzy_connect['inst'] != \"\")]\n",
    "#new_connects = new_connects[['inst', 'grid_id']].drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "#main_insts = pd.concat([main_insts, new_connects], ignore_index=True)\n",
    "#main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "#### Remove matches from solr_insts:\n",
    "#solr_insts = pd.merge(solr_insts, new_connects, how='left', on = 'inst')\n",
    "#solr_insts = solr_insts[solr_insts['grid_id'].isnull()].drop('grid_id', axis = 1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "###############\n",
    " ### Fuzzy matching em inst on the insts in main_insts:\n",
    "###############\n",
    "#### Use kneighbors_fuzzy_match() to get fuzzy matches\n",
    "em_insts_2 = em_insts.drop_duplicates(subset=['Institute'], keep = 'first').reset_index(drop = True)\n",
    "em_insts_2 = em_insts_2['Institute']\n",
    "em_fuzzy_connect = kneighbors_fuzzy_match(em_insts_2, main_insts['inst'], main_insts['grid_id'])\n",
    "em_fuzzy_connect\n",
    "#### Connect matches to main_insts:\n",
    "new_connects = em_fuzzy_connect[(em_fuzzy_connect['Match confidence (lower is better)'] < 0.36) & (em_fuzzy_connect['Match confidence (lower is better)'] > 0) & (em_fuzzy_connect['inst'] != \"\")]\n",
    "new_connects = new_connects[['inst', 'grid_id']].drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "main_insts = pd.concat([main_insts, new_connects], ignore_index=True)\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "#### Remove matches from em_insts:\n",
    "em_insts = pd.merge(em_insts, new_connects, how='left', left_on= 'Institute', right_on = 'inst')\n",
    "em_insts = em_insts[em_insts['grid_id'].isnull()].drop(['grid_id', 'inst'], axis = 1).reset_index(drop=True)\n",
    "em_insts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ry2sm8M8Xof"
   },
   "source": [
    "# Final removal of inaccurate main_insts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "H0xbKDyu8V22",
    "outputId": "c8e0266b-a230-43e8-a24d-93ed2ab92e0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst</th>\n",
       "      <th>grid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University of Chinese Academy of Sciences, Bei...</td>\n",
       "      <td>grid.410726.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Basel, Basel</td>\n",
       "      <td>grid.6612.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harvard Medical School, Boston, Massachusetts</td>\n",
       "      <td>grid.471403.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Swiss Tropical and Public Health Institute, Basel</td>\n",
       "      <td>grid.416786.a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fogarty International Center, National Institu...</td>\n",
       "      <td>grid.453035.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716201</th>\n",
       "      <td>Laboratoire Cardioprotection, Remodelage et Th...</td>\n",
       "      <td>grid.7252.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716202</th>\n",
       "      <td>Division of Nephrology, Escola Paulista de Med...</td>\n",
       "      <td>grid.411249.b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716203</th>\n",
       "      <td>Center for Fetal Programming</td>\n",
       "      <td>grid.6203.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716204</th>\n",
       "      <td>Jiangsu Kanion Pharmarceutical, Ltd.</td>\n",
       "      <td>grid.452789.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716205</th>\n",
       "      <td>School of Medicine, Tzu Chi University</td>\n",
       "      <td>grid.412019.f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716206 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     inst        grid_id\n",
       "0       University of Chinese Academy of Sciences, Bei...  grid.410726.6\n",
       "1                              University of Basel, Basel    grid.6612.3\n",
       "2           Harvard Medical School, Boston, Massachusetts  grid.471403.5\n",
       "3       Swiss Tropical and Public Health Institute, Basel  grid.416786.a\n",
       "4       Fogarty International Center, National Institu...  grid.453035.4\n",
       "...                                                   ...            ...\n",
       "716201  Laboratoire Cardioprotection, Remodelage et Th...    grid.7252.2\n",
       "716202  Division of Nephrology, Escola Paulista de Med...  grid.411249.b\n",
       "716203                       Center for Fetal Programming    grid.6203.7\n",
       "716204               Jiangsu Kanion Pharmarceutical, Ltd.  grid.452789.5\n",
       "716205             School of Medicine, Tzu Chi University  grid.412019.f\n",
       "\n",
       "[716206 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################\n",
    " ## Final removal of main_insts\n",
    "###################################################\n",
    "###############\n",
    " ### For the new connects from the main_inst fuzzy match, exclude startswith('Department of'\n",
    "###############\n",
    "a = main_insts[700000:]\n",
    "a = a[~a['inst'].str.startswith('Department of', na=False)]\n",
    "b = main_insts[:700000]\n",
    "main_insts = pd.concat([b,a], ignore_index=True)\n",
    "\n",
    "###############\n",
    " ### De-dup and remove where inst is only numbers:\n",
    "###############\n",
    "main_insts = main_insts[main_insts['inst'].notnull()]\n",
    "main_insts = main_insts.drop_duplicates(subset=['inst'], keep = 'first').reset_index(drop = True)\n",
    "main_insts = main_insts[~main_insts['inst'].str.isnumeric()].reset_index(drop = True)\n",
    "\n",
    "###############\n",
    " ### Remove where the character len of inst is '2 or under' or 'over 425'\n",
    "###############\n",
    "main_insts['char_len'] = main_insts['inst'].str.len()\n",
    "main_insts = main_insts[(main_insts['char_len'] > 2) & (main_insts['char_len'] < 425)].drop('char_len', axis=1).reset_index(drop = True)\n",
    "\n",
    "###############\n",
    " ### Common non-'Education' GRID connections (over 90 rows in main_insts) that should be excluded from main_insts list: \n",
    "###############\n",
    "grid_ids_to_remove = [\"grid.466117.3\", \"grid.462718.e\", \"grid.449710.f\", \"grid.495658.3\", \"grid.426602.4\", \"grid.418761.d\", \"grid.467642.5\", \"grid.466112.6\", \"grid.419475.a\", \"grid.414102.2\", \"grid.417768.b\", \"grid.462937.d\", \"grid.501573.5\", \"grid.414070.6\"]\n",
    "    # NOTE: These are the grid_ids to remove from main_insts (way too generic)\n",
    "      # These are their names: [\"Department of Biological Sciences\", \"Department of Virology\", \"University Hospital\", \"Institute of Biology\", \"Institute of Virology\", \"Institute of Immunology\", \"Center for Global Health\", \"Department of Mathematical Sciences\", \"National Institute on Aging\", \"Department of Health\", \"Center for Cancer Research\", \"Computer Science Department\", \"Department of Archaeology\", \"Children's Hospital\"]\n",
    "main_insts = main_insts[~main_insts['grid_id'].isin(grid_ids_to_remove)].reset_index(drop = True)\n",
    "\n",
    "###############\n",
    " ### Download main_insts again:\n",
    "###############\n",
    "#from google.colab import files\n",
    "#main_insts.to_csv('main_insts.csv')\n",
    "#files.download('main_insts.csv')\n",
    "\n",
    "main_insts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgNUxroZNSKs"
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    " ## Quick metrics:\n",
    "##################################################\n",
    "###############\n",
    " ### Solr institution metrics\n",
    "###############\n",
    "  # 1,021,536 out of 1,189,751 total institutions were matched (86%).\n",
    "  # 521,394 out of 661,753 unique institutions were matched (79%).\n",
    "###############\n",
    " ### EM institution metrics\n",
    "###############\n",
    "  # 2,073,332 out of 4,112,509 total institutions were matched (50%).\n",
    "  # 232,491 out of 500,908 unique institutions were matched (46%).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "SPiGTquGjnBM",
    "outputId": "ca535e38-ae97-4bcc-a682-64bef4b01013"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_3080a644-55de-482e-a2d4-9b41632f5fd9\", \"main_insts.csv\", 74012467)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################################################\n",
    " ## Export/download the data\n",
    "##################################################\n",
    "###############\n",
    " ### Download main_insts\n",
    "###############\n",
    "from google.colab import files\n",
    "main_insts.to_csv('main_insts.csv')\n",
    "files.download('main_insts.csv')\n",
    "\n",
    "###############\n",
    " ### Download em_insts\n",
    "###############\n",
    "#em_insts.to_csv('em_insts.csv')\n",
    "#files.download('em_insts.csv')\n",
    "\n",
    "###############\n",
    " ### Download solr_insts\n",
    "###############\n",
    "#solr_insts.to_csv('solr_insts.csv')\n",
    "#files.download('solr_insts.csv')\n",
    "\n",
    "###############\n",
    " ### Download grid_insts (in case you want the inst_connect column already there)\n",
    "###############\n",
    "#grid_insts.to_csv('grid_insts.csv')\n",
    "#files.download('grid_insts.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Inst_disambig_final_draft",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
